{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate_video.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastianLarssonDTU/02456-Reinforcement-Learning-Project/blob/before_framestacking/Generate_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6jlWJKXBo0m"
      },
      "source": [
        "# INIT : Procgen, Drive, Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mmSs5ItNLLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e44dca-ab45-40cc-c6ac-edbb7d17d210"
      },
      "source": [
        "!pip install procgen"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: procgen in /usr/local/lib/python3.6/dist-packages (0.10.4)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (3.0.12)\n",
            "Requirement already satisfied: gym<1.0.0,>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (0.17.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (1.18.5)\n",
            "Requirement already satisfied: gym3<1.0.0,>=0.3.3 in /usr/local/lib/python3.6/dist-packages (from procgen) (0.3.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.5.0)\n",
            "Requirement already satisfied: glfw<2.0.0,>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.12.0)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.14.3)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (2.9.0)\n",
            "Requirement already satisfied: moderngl<6.0.0,>=5.5.4 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (5.6.2)\n",
            "Requirement already satisfied: imageio-ffmpeg<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (0.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<1.0.0,>=0.15.0->procgen) (0.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi<2.0.0,>=1.13.0->gym3<1.0.0,>=0.3.3->procgen) (2.20)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0.0,>=2.6.0->gym3<1.0.0,>=0.3.3->procgen) (7.0.0)\n",
            "Requirement already satisfied: glcontext<3,>=2 in /usr/local/lib/python3.6/dist-packages (from moderngl<6.0.0,>=5.5.4->gym3<1.0.0,>=0.3.3->procgen) (2.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RgF6myEA6WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70b7c7c-840d-4ecf-d894-93350e781907"
      },
      "source": [
        "#Clone git\n",
        "!git clone -b before_framestacking https://github.com/SebastianLarssonDTU/02456-Reinforcement-Learning-Project.git \"my_project\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'my_project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-jsbleFHMz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c8f039-8b00-4fa0-8015-794ccf5758ba"
      },
      "source": [
        "#update git\n",
        "%cd /content/my_project\n",
        "! git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/my_project\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 18 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n",
            "From https://github.com/SebastianLarssonDTU/02456-Reinforcement-Learning-Project\n",
            "   ca514f1..6341b4d  before_framestacking -> origin/before_framestacking\n",
            "Updating ca514f1..6341b4d\n",
            "Fast-forward\n",
            " Generate_video.ipynb | 390 \u001b[32m+++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m----------\u001b[m\n",
            " Videos/README.md     |   6 \u001b[32m+\u001b[m\n",
            " 2 files changed, 319 insertions(+), 77 deletions(-)\n",
            " create mode 100644 Videos/README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abnnrXLuB6Ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1db5837-e774-4262-a305-de7ca40bc7fb"
      },
      "source": [
        "import datatools as tools\n",
        "from datatools import DATA_PATH, MODEL_PATH\n",
        "#Mount drive\n",
        "tools.mount_drive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBb1c_XBBsNl"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XmB8QZ7BQIW"
      },
      "source": [
        "#Import all custom files\n",
        "import baseline\n",
        "import datatools as tools\n",
        "import hyperparameters as h\n",
        "import model\n",
        "import my_util\n",
        "import policy\n",
        "import ppo\n",
        "import utils\n",
        "\n",
        "#other imports\n",
        "import torch\n",
        "\n",
        "#import specific methods\n",
        "from baseline import set_hyperparameters\n",
        "from ppo import PPO\n",
        "from experiments import run_experiment, print_list_of_experiments\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzaVLDqAbn8H"
      },
      "source": [
        "# run_experiment(2, levels=50, save_interval=5e5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtqCRcRItR5N"
      },
      "source": [
        "# #for Experiment 7\n",
        "# file_name = \"Experiment7_50levels_Run_04Dec_18h12m45s_loaded_05Dec_10h49m07s_13516800steps\"\n",
        "# set_hyperparameters(baseline=\"Impala\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 50\n",
        "# h.batch_size=512\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# model.load_policy(file_name)\n",
        "# model.train()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnI_7VnNnUQq"
      },
      "source": [
        "# #For Experiment 2\n",
        "# file_name = \"Experiment2_50levels_Run_04Dec_18h10m32s_loaded_05Dec_09h43m36s_13516800steps\"\n",
        "# set_hyperparameters(baseline=\"PPO\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 50\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# model.load_policy(file_name)\n",
        "# model.train()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxtED-_-kn6W"
      },
      "source": [
        "# #for Experiment 8\n",
        "# file_name = \"Experiment8_50levels_Run_05Dec_08h34m02s_4005888steps\"\n",
        "# set_hyperparameters(baseline=\"Impala\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 50\n",
        "# h.batch_size=512\n",
        "# h.death_penalty = True\n",
        "# h.penalty = 5\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# model.load_policy(file_name)\n",
        "# model.train()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fDrhCodCusg"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDLiAWVNTeCT"
      },
      "source": [
        "# Generate video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0vtTg1aTfS9"
      },
      "source": [
        "from utils import make_env\n",
        "import imageio\n",
        "\n",
        "def old_policy_evaluation(model, video_name=None, print_output=True, test_on_training=False, off_set = 0):\n",
        "  policy = model.policy\n",
        "\n",
        "  if video_name is None:\n",
        "    video_name = model.file_name\n",
        "  # Make evaluation environment\n",
        "  if test_on_training:\n",
        "    eval_env = make_env(model.num_envs, num_levels=model.num_levels)\n",
        "    video_name += \"_TEST_ON_TRAINING\"\n",
        "  else:\n",
        "    eval_env = make_env(model.num_envs, start_level=model.num_levels+off_set, num_levels=model.num_levels)\n",
        "  obs = eval_env.reset()\n",
        "\n",
        "  frames = []\n",
        "  total_reward = []\n",
        "\n",
        "  # Evaluate policy\n",
        "  policy.eval()\n",
        "  # for _ in range(512):  #<--- Hardcoded batch size?\n",
        "  while True:\n",
        "    # Use policy\n",
        "    action, log_prob, value = policy.act(obs)\n",
        "\n",
        "    # Take step in environment\n",
        "    obs, reward, done, info = eval_env.step(action)\n",
        "    total_reward.append(torch.Tensor(reward))\n",
        "\n",
        "    # Render environment and store\n",
        "    frame = (torch.Tensor(eval_env.render(mode='rgb_array'))*255.).byte()\n",
        "    frames.append(frame)\n",
        "    if done[0]:\n",
        "      break\n",
        "\n",
        "  # Calculate average return\n",
        "  total_reward = torch.stack(total_reward).sum(0).mean(0)\n",
        "  \n",
        "  if print_output:\n",
        "    print('Average return:', total_reward)\n",
        "\n",
        "  # Save frames as video\n",
        "  frames = torch.stack(frames).cpu().numpy()\n",
        "  imageio.mimsave(video_name+'.mp4', frames, fps=25)\n",
        "  \n",
        "  return total_reward"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMamEG4J3y_Y"
      },
      "source": [
        "## New code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qEudAuH30xd"
      },
      "source": [
        "from utils import make_env\n",
        "import imageio\n",
        "\n",
        "VIDEO_PATH = '/content/drive/My Drive/02456-Deep-Learning-Project/Videos/'\n",
        "\n",
        "def generate_videos(model, video_name=None, print_output=True, test_on_training=False, off_set = 0, nr_of_levels=5, save_video=False, dist_mode=\"easy\"):\n",
        "  policy = model.policy\n",
        "\n",
        "  if video_name is None:\n",
        "    video_name = model.file_name\n",
        "  \n",
        "  # Make evaluation environment\n",
        "  if test_on_training:\n",
        "    eval_env = make_env(model.num_envs, num_levels=model.num_levels, normalize_reward = False, dist_mode=dist_mode)\n",
        "    video_name += \"_TEST_ON_TRAINING\"\n",
        "  else:\n",
        "    eval_env = make_env(model.num_envs, start_level=model.num_levels+off_set, num_levels=model.num_levels, normalize_reward = False, dist_mode=dist_mode)\n",
        "  obs = eval_env.reset()\n",
        "\n",
        "  frames = []\n",
        "  total_reward = []\n",
        "  level_counter=1\n",
        "  # Evaluate policy\n",
        "  policy.eval()\n",
        "\n",
        "  while True:\n",
        "    \n",
        "    # Use policy\n",
        "    action, log_prob, value = policy.act(obs)\n",
        "\n",
        "    # Take step in environment\n",
        "    obs, reward, done, info = eval_env.step(action)\n",
        "    total_reward.append(torch.Tensor(reward))\n",
        "\n",
        "    # Render environment and store\n",
        "    frame = (torch.Tensor(eval_env.render(mode='rgb_array'))*255.).byte()\n",
        "    frames.append(frame)\n",
        "    if done[0]: #next level\n",
        "      #Calculate level reward\n",
        "      level_reward = torch.stack(total_reward).sum(0)[0]\n",
        "      \n",
        "      if save_video:\n",
        "        # Save frames as video\n",
        "        frames = torch.stack(frames).cpu().numpy()\n",
        "        name = video_name+'_level{:d}_reward{:.0f}.mp4'.format(level_counter, level_reward)\n",
        "        imageio.mimsave(VIDEO_PATH + name, frames, fps=25)\n",
        "        print(\"Saved video: {}\".format(name))\n",
        "      else:\n",
        "        print(level_counter)\n",
        "        print(level_reward)\n",
        "      \n",
        "      #check if all levels done\n",
        "      level_counter +=1\n",
        "      if level_counter > nr_of_levels:\n",
        "        break #done testing\n",
        "\n",
        "      #reset variables for next level\n",
        "      frames=[]\n",
        "      total_reward = []"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXwJ1wJKUiB_"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb1gG-VSIjBP"
      },
      "source": [
        "### Impala DP 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmNwpDslUgTT"
      },
      "source": [
        "# #for Experiment 8\n",
        "# file_name = \"Experiment8_200levels_Run_06Dec_16h17m59s_loaded_08Dec_13h28m10s_8028160steps\"\n",
        "# set_hyperparameters(baseline=\"Impala\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 200\n",
        "# h.batch_size=512\n",
        "# h.death_penalty = True\n",
        "# h.penalty = 5\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# policy = model.load_policy(file_name)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yqDwvk_VdKw"
      },
      "source": [
        "# old_policy_evaluation(model, test_on_training=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjKZxk7R7LjX"
      },
      "source": [
        "# generate_videos(model, video_name=\"Final_Impala_dp5_200levels_test10\", save_video=True, nr_of_levels=10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYCccJG0EZD0"
      },
      "source": [
        "# generate_videos(model, video_name=\"Final_Impala_dp5_200levels_test10\", save_video=True, nr_of_levels=10, test_on_training=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0i_LTZ5eK2d"
      },
      "source": [
        "### Impala no penalty 200 levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05C_jfnteQdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a3fdc3-cc9f-4821-bcb4-9bc7c5db921b"
      },
      "source": [
        "# #for Experiment 7\n",
        "# file_name = \"Experiment7_200levels_Run_06Dec_16h18m31s_loaded_08Dec_14h21m55s_8019968steps\"\n",
        "# set_hyperparameters(baseline=\"Impala\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 200\n",
        "# h.batch_size=512\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# model.load_policy(file_name)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment7_200levels_Run_06Dec_16h18m31s_loaded_08Dec_14h21m55s_8019968steps.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Policy(\n",
              "  (encoder): ImpalaEncoder(\n",
              "    (block1): ImpalaBlock(\n",
              "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (res1): ResidualBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (res2): ResidualBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (block2): ImpalaBlock(\n",
              "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (res1): ResidualBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (res2): ResidualBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (block3): ImpalaBlock(\n",
              "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (res1): ResidualBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (res2): ResidualBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  )\n",
              "  (policy): Linear(in_features=512, out_features=15, bias=True)\n",
              "  (value): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f1eLNRvIxlo"
      },
      "source": [
        "# generate_videos(model, video_name=\"Final_Impala_200levels_test10\", save_video=True, nr_of_levels=10)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQIIkFQzI1Ld"
      },
      "source": [
        "# generate_videos(model, video_name=\"Final_Impala_200levels_test10\", save_video=True, nr_of_levels=10, test_on_training=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUJucmgCebOs"
      },
      "source": [
        "# total_reward, rewards = model.evaluate_policy(20,normalize_reward=False)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWGL4E53OqpP"
      },
      "source": [
        "# import pandas as pd\r\n",
        "# df = pd.DataFrame(rewards)\r\n",
        "# df.to_csv(VIDEO_PATH+\"Impala_200levels_test20.csv\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzEsDEaiOwC4"
      },
      "source": [
        "# model.num_levels=0\r\n",
        "# total_reward2, rewards2 = model.evaluate_policy(20,normalize_reward=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEN3xhsFO01z"
      },
      "source": [
        "# df2 = pd.DataFrame(rewards2)\r\n",
        "# df2.to_csv(VIDEO_PATH+\"Impala_200levels_test20_TEST_ON_TRAINING.csv\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O7TOF7Wfq0Z"
      },
      "source": [
        "### PPO 200 levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZrwNZ6mfq0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377b3389-c248-4c3e-c851-707fdcfbb170"
      },
      "source": [
        "#For Experiment 2\n",
        "file_name = \"Experiment2_200levels_Run_07Dec_13h49m13s_loaded_08Dec_17h00m43s_8126464steps\"\n",
        "set_hyperparameters(baseline=\"PPO\")\n",
        "h.value_clipping = True\n",
        "h.num_levels = 200\n",
        "model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "policy=model.load_policy(file_name)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment2_200levels_Run_07Dec_13h49m13s_loaded_08Dec_17h00m43s_8126464steps.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7hS8m4fq0a"
      },
      "source": [
        "# for i in range(4):\n",
        "#   result=old_policy_evaluation(model, video_name=\"PPO_200levels_{}\".format(i), off_set=i, print_output=False)\n",
        "#   print(\"{}: {}\".format(i, result))\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEenEv_DhxGP"
      },
      "source": [
        "# old_policy_evaluation(model, test_on_training=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYIEoz--iNx2"
      },
      "source": [
        "# generate_videos(model, video_name=\"Final_ppo_200levels_test10\", save_video=True, nr_of_levels=10)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g06lJJw-LAc1"
      },
      "source": [
        "# generate_videos(model, video_name=\"Final_ppo_200levels_test10\", save_video=True, nr_of_levels=10, test_on_training=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtfwHux1LE0U"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhTuUMvDRIN0"
      },
      "source": [
        "total_reward, rewards = model.evaluate_policy(20,normalize_reward=False)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTx6c96QRIN6"
      },
      "source": [
        "import pandas as pd\r\n",
        "df = pd.DataFrame(rewards)\r\n",
        "df.to_csv(VIDEO_PATH+\"ppo_200levels_test20.csv\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MviRAsz3RIN7"
      },
      "source": [
        "model.num_levels=0\r\n",
        "total_reward2, rewards2 = model.evaluate_policy(20,normalize_reward=False)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSDRFyhDRIN8"
      },
      "source": [
        "df2 = pd.DataFrame(rewards2)\r\n",
        "df2.to_csv(VIDEO_PATH+\"ppo_200levels_test20_TEST_ON_TRAINING.csv\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dmW1bIAT_XZ"
      },
      "source": [
        "I do not think this works! because 20 levels from num_levels=200 is not the same as num_levels=20. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhUBnQ_ERTQY",
        "outputId": "d9203809-2e8b-4631-bb7b-911c5457e253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_reward"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.534375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcja8zlsT4rO",
        "outputId": "c8518ab6-c503-43e7-db3e-ad5c21849b40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_reward2"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.9390625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvcvoSFNT6HL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}