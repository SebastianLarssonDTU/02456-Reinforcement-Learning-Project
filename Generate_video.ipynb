{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate_video.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastianLarssonDTU/02456-Reinforcement-Learning-Project/blob/before_framestacking/Generate_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6jlWJKXBo0m"
      },
      "source": [
        "# INIT : Procgen, Drive, Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mmSs5ItNLLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a0d953-f2d3-4a68-b291-f036524e8291"
      },
      "source": [
        "!pip install procgen"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting procgen\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/34/0ae32b01ec623cd822752e567962cfa16ae9c6d6ba2208f3445c017a121b/procgen-0.10.4-cp36-cp36m-manylinux2010_x86_64.whl (39.9MB)\n",
            "\u001b[K     |████████████████████████████████| 39.9MB 83kB/s \n",
            "\u001b[?25hCollecting gym3<1.0.0,>=0.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/8c/83da801207f50acfd262041e7974f3b42a0e5edd410149d8a70fd4ad2e70/gym3-0.3.3-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym<1.0.0,>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (0.17.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (1.18.5)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (3.0.12)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.14.3)\n",
            "Collecting imageio<3.0.0,>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 53.8MB/s \n",
            "\u001b[?25hCollecting moderngl<6.0.0,>=5.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/ab/5f72a1b7c5bdbb17160c85e8ba855d48925c74ff93c1e1027d5ad40bf33c/moderngl-5.6.2-cp36-cp36m-manylinux1_x86_64.whl (664kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 50.5MB/s \n",
            "\u001b[?25hCollecting glfw<2.0.0,>=1.8.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/1b/cc758368f1b2466b3701c0f692973aa8a0b51a192a40463c1d02d54d640c/glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 55.1MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/12/01126a2fb737b23461d7dadad3b8abd51ad6210f979ff05c6fa9812dfbbe/imageio_ffmpeg-0.3.0-py3-none-manylinux2010_x86_64.whl (22.2MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi<2.0.0,>=1.13.0->gym3<1.0.0,>=0.3.3->procgen) (2.20)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0.0,>=2.6.0->gym3<1.0.0,>=0.3.3->procgen) (7.0.0)\n",
            "Collecting glcontext<3,>=2\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/8d/93915df9cd8d31c5f054bbacd1c7a76cd2f776b8212dcc768358bd2d4a37/glcontext-2.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<1.0.0,>=0.15.0->procgen) (0.16.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: imageio, glcontext, moderngl, glfw, imageio-ffmpeg, gym3, procgen\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed glcontext-2.2.0 glfw-1.12.0 gym3-0.3.3 imageio-2.9.0 imageio-ffmpeg-0.3.0 moderngl-5.6.2 procgen-0.10.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RgF6myEA6WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d50d568-688a-4938-a693-f0e486c188fb"
      },
      "source": [
        "#Clone git\n",
        "!git clone -b before_framestacking https://github.com/SebastianLarssonDTU/02456-Reinforcement-Learning-Project.git \"my_project\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'my_project'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 624 (delta 99), reused 4 (delta 0), pack-reused 460\u001b[K\n",
            "Receiving objects: 100% (624/624), 12.08 MiB | 16.81 MiB/s, done.\n",
            "Resolving deltas: 100% (382/382), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-jsbleFHMz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60fe53a-0e54-4a94-bd3f-bf480e9adb0a"
      },
      "source": [
        "#update git\n",
        "%cd /content/my_project\n",
        "! git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/my_project\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abnnrXLuB6Ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df54d30a-0bbd-4813-80a5-e152d6937dd6"
      },
      "source": [
        "import datatools as tools\n",
        "from datatools import DATA_PATH, MODEL_PATH\n",
        "#Mount drive\n",
        "tools.mount_drive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBb1c_XBBsNl"
      },
      "source": [
        "# TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XmB8QZ7BQIW"
      },
      "source": [
        "#Import all custom files\n",
        "import baseline\n",
        "import datatools as tools\n",
        "import hyperparameters as h\n",
        "import model\n",
        "import my_util\n",
        "import policy\n",
        "import ppo\n",
        "import utils\n",
        "\n",
        "#other imports\n",
        "import torch\n",
        "\n",
        "#import specific methods\n",
        "from baseline import set_hyperparameters\n",
        "from ppo import PPO\n",
        "from experiments import run_experiment, print_list_of_experiments\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzaVLDqAbn8H"
      },
      "source": [
        "# run_experiment(2, levels=50, save_interval=5e5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtqCRcRItR5N"
      },
      "source": [
        "# #for Experiment 7\n",
        "# file_name = \"Experiment7_50levels_Run_04Dec_18h12m45s_loaded_05Dec_10h49m07s_13516800steps\"\n",
        "# set_hyperparameters(baseline=\"Impala\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 50\n",
        "# h.batch_size=512\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# model.load_policy(file_name)\n",
        "# model.train()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnI_7VnNnUQq"
      },
      "source": [
        "# #For Experiment 2\n",
        "# file_name = \"Experiment2_50levels_Run_04Dec_18h10m32s_loaded_05Dec_09h43m36s_13516800steps\"\n",
        "# set_hyperparameters(baseline=\"PPO\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 50\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# model.load_policy(file_name)\n",
        "# model.train()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxtED-_-kn6W"
      },
      "source": [
        "# #for Experiment 8\n",
        "# file_name = \"Experiment8_50levels_Run_05Dec_08h34m02s_4005888steps\"\n",
        "# set_hyperparameters(baseline=\"Impala\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 50\n",
        "# h.batch_size=512\n",
        "# h.death_penalty = True\n",
        "# h.penalty = 5\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# model.load_policy(file_name)\n",
        "# model.train()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fDrhCodCusg"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDLiAWVNTeCT"
      },
      "source": [
        "# Generate video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0vtTg1aTfS9"
      },
      "source": [
        "from utils import make_env\n",
        "import imageio\n",
        "\n",
        "def old_policy_evaluation(model, video_name=None, print_output=True, test_on_training=False, off_set = 0):\n",
        "  policy = model.policy\n",
        "\n",
        "  if video_name is None:\n",
        "    video_name = model.file_name\n",
        "  # Make evaluation environment\n",
        "  if test_on_training:\n",
        "    eval_env = make_env(model.num_envs, num_levels=model.num_levels)\n",
        "    video_name += \"_TEST_ON_TRAINING\"\n",
        "  else:\n",
        "    eval_env = make_env(model.num_envs, start_level=model.num_levels+off_set, num_levels=model.num_levels)\n",
        "  obs = eval_env.reset()\n",
        "\n",
        "  frames = []\n",
        "  total_reward = []\n",
        "\n",
        "  # Evaluate policy\n",
        "  policy.eval()\n",
        "  # for _ in range(512):  #<--- Hardcoded batch size?\n",
        "  while True:\n",
        "    # Use policy\n",
        "    action, log_prob, value = policy.act(obs)\n",
        "\n",
        "    # Take step in environment\n",
        "    obs, reward, done, info = eval_env.step(action)\n",
        "    total_reward.append(torch.Tensor(reward))\n",
        "\n",
        "    # Render environment and store\n",
        "    frame = (torch.Tensor(eval_env.render(mode='rgb_array'))*255.).byte()\n",
        "    frames.append(frame)\n",
        "    if done[0]:\n",
        "      break\n",
        "\n",
        "  # Calculate average return\n",
        "  total_reward = torch.stack(total_reward).sum(0).mean(0)\n",
        "  \n",
        "  if print_output:\n",
        "    print('Average return:', total_reward)\n",
        "\n",
        "  # Save frames as video\n",
        "  frames = torch.stack(frames).cpu().numpy()\n",
        "  imageio.mimsave(video_name+'.mp4', frames, fps=25)\n",
        "  \n",
        "  return total_reward"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMamEG4J3y_Y"
      },
      "source": [
        "## New code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qEudAuH30xd"
      },
      "source": [
        "from utils import make_env\n",
        "import imageio\n",
        "\n",
        "def generate_videos(model, video_name=None, print_output=True, test_on_training=False, off_set = 0, nr_of_levels=5, save_video=False):\n",
        "  policy = model.policy\n",
        "\n",
        "  if video_name is None:\n",
        "    video_name = model.file_name\n",
        "  \n",
        "  # Make evaluation environment\n",
        "  if test_on_training:\n",
        "    eval_env = make_env(model.num_envs, num_levels=nr_of_levels, normalize_reward = False)\n",
        "    video_name += \"_TEST_ON_TRAINING\"\n",
        "  else:\n",
        "    eval_env = make_env(model.num_envs, start_level=model.num_levels+off_set, num_levels=nr_of_levels, normalize_reward = False)\n",
        "  obs = eval_env.reset()\n",
        "\n",
        "  frames = []\n",
        "  total_reward = []\n",
        "  level_counter=1\n",
        "  # Evaluate policy\n",
        "  policy.eval()\n",
        "\n",
        "  while True:\n",
        "    \n",
        "    # Use policy\n",
        "    action, log_prob, value = policy.act(obs)\n",
        "\n",
        "    # Take step in environment\n",
        "    obs, reward, done, info = eval_env.step(action)\n",
        "    total_reward.append(torch.Tensor(reward))\n",
        "\n",
        "    # Render environment and store\n",
        "    frame = (torch.Tensor(eval_env.render(mode='rgb_array'))*255.).byte()\n",
        "    frames.append(frame)\n",
        "    if done[0]: #next level\n",
        "      #Calculate level reward\n",
        "      level_reward = torch.stack(total_reward).sum(0)[0]\n",
        "      \n",
        "      if save_video:\n",
        "        # Save frames as video\n",
        "        frames = torch.stack(frames).cpu().numpy()\n",
        "        name = video_name+'_level{:d}_reward{:.0f}.mp4'.format(level_counter, level_reward)\n",
        "        imageio.mimsave(name, frames, fps=25)\n",
        "        print(\"Saved video: {}\".format(name))\n",
        "      else:\n",
        "        print(level_counter)\n",
        "        print(level_reward)\n",
        "      \n",
        "      #check if all levels done\n",
        "      level_counter +=1\n",
        "      if level_counter > nr_of_levels:\n",
        "        break #done testing\n",
        "\n",
        "      #reset variables for next level\n",
        "      frames=[]\n",
        "      total_reward = []"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXwJ1wJKUiB_"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmNwpDslUgTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae48409d-8009-45b6-e0af-d3c012d18145"
      },
      "source": [
        "#for Experiment 8\n",
        "file_name = \"Experiment8_200levels_Run_06Dec_16h17m59s_loaded_08Dec_10h26m35s_5021696steps\"\n",
        "set_hyperparameters(baseline=\"Impala\")\n",
        "h.value_clipping = True\n",
        "h.num_levels = 200\n",
        "h.batch_size=512\n",
        "h.death_penalty = True\n",
        "h.penalty = 5\n",
        "model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "model.load_policy(file_name)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment8_200levels_Run_06Dec_16h17m59s_loaded_08Dec_10h26m35s_5021696steps.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Policy(\n",
              "  (encoder): ImpalaEncoder(\n",
              "    (block1): ImpalaBlock(\n",
              "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (res1): ResidualBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (res2): ResidualBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (block2): ImpalaBlock(\n",
              "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (res1): ResidualBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (res2): ResidualBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (block3): ImpalaBlock(\n",
              "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (res1): ResidualBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (res2): ResidualBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  )\n",
              "  (policy): Linear(in_features=512, out_features=15, bias=True)\n",
              "  (value): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yqDwvk_VdKw"
      },
      "source": [
        "# old_policy_evaluation(model, test_on_training=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pVNOnN6WPIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d01d6b4-4be3-4b31-e17b-0b58eb9a99f6"
      },
      "source": [
        "model.evaluate_policy(5, normalize_reward=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33.0125,\n",
              " {0: [39.0, 28.0, 19.0, 32.0, 7.0],\n",
              "  1: [6.0, 17.0, 7.0, 36.0, 39.0],\n",
              "  2: [62.0, 69.0, 51.0, 4.0, 14.0],\n",
              "  3: [39.0, 21.0, 5.0, 9.0, 59.0],\n",
              "  4: [7.0, 35.0, 5.0, 21.0, 15.0],\n",
              "  5: [10.0, 7.0, 49.0, 29.0, 62.0],\n",
              "  6: [34.0, 3.0, 17.0, 4.0, 68.0],\n",
              "  7: [64.0, 47.0, 52.0, 61.0, 4.0],\n",
              "  8: [7.0, 68.0, 7.0, 59.0, 45.0],\n",
              "  9: [57.0, 13.0, 56.0, 37.0, 6.0],\n",
              "  10: [15.0, 38.0, 38.0, 58.0, 21.0],\n",
              "  11: [70.0, 50.0, 2.0, 65.0, 69.0],\n",
              "  12: [6.0, 6.0, 56.0, 58.0, 5.0],\n",
              "  13: [62.0, 4.0, 56.0, 12.0, 43.0],\n",
              "  14: [41.0, 51.0, 70.0, 68.0, 17.0],\n",
              "  15: [7.0, 10.0, 14.0, 15.0, 56.0],\n",
              "  16: [59.0, 45.0, 57.0, 64.0, 16.0],\n",
              "  17: [67.0, 67.0, 47.0, 66.0, 37.0],\n",
              "  18: [38.0, 4.0, 8.0, 14.0, 19.0],\n",
              "  19: [8.0, 53.0, 68.0, 55.0, 5.0],\n",
              "  20: [71.0, 62.0, 10.0, 59.0, 52.0],\n",
              "  21: [46.0, 33.0, 7.0, 58.0, 66.0],\n",
              "  22: [14.0, 15.0, 63.0, 14.0, 29.0],\n",
              "  23: [29.0, 7.0, 18.0, 10.0, 32.0],\n",
              "  24: [13.0, 49.0, 5.0, 59.0, 4.0],\n",
              "  25: [26.0, 56.0, 7.0, 9.0, 65.0],\n",
              "  26: [17.0, 22.0, 65.0, 39.0, 17.0],\n",
              "  27: [9.0, 44.0, 19.0, 4.0, 72.0],\n",
              "  28: [18.0, 14.0, 36.0, 47.0, 17.0],\n",
              "  29: [68.0, 4.0, 7.0, 12.0, 32.0],\n",
              "  30: [29.0, 4.0, 22.0, 20.0, 49.0],\n",
              "  31: [65.0, 16.0, 67.0, 63.0, 4.0]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43z96r6o24AI",
        "outputId": "01010322-9918-4d80-bf81-424a042b4e58"
      },
      "source": [
        "model.evaluate_policy(5, normalize_reward=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.602030308544636,\n",
              " {0: [21.66693340241909,\n",
              "   6.668309599161148,\n",
              "   4.558768928050995,\n",
              "   7.732477232813835,\n",
              "   1.7077887654304504],\n",
              "  1: [15.279632449150085,\n",
              "   4.842270344495773,\n",
              "   1.6627369225025177,\n",
              "   8.568100154399872,\n",
              "   9.482200741767883],\n",
              "  2: [18.68360722064972,\n",
              "   16.605701461434364,\n",
              "   12.543238922953606,\n",
              "   0.9899160414934158,\n",
              "   3.4640539586544037],\n",
              "  3: [24.464234605431557,\n",
              "   4.977383449673653,\n",
              "   1.1971215158700943,\n",
              "   2.1559195816516876,\n",
              "   14.355506390333176],\n",
              "  4: [16.490240216255188,\n",
              "   9.38219590485096,\n",
              "   1.1791674196720123,\n",
              "   5.01148396730423,\n",
              "   3.6015762239694595],\n",
              "  5: [6.894734710454941,\n",
              "   2.0540365874767303,\n",
              "   11.68256014585495,\n",
              "   6.975977569818497,\n",
              "   15.218755930662155],\n",
              "  6: [25.987394779920578,\n",
              "   0.6983423382043839,\n",
              "   4.0503754913806915,\n",
              "   0.9580339789390564,\n",
              "   16.429210543632507],\n",
              "  7: [22.784125417470932,\n",
              "   11.250742793083191,\n",
              "   12.675657376646996,\n",
              "   15.099013596773148,\n",
              "   0.985857218503952],\n",
              "  8: [9.350831896066666,\n",
              "   16.974804624915123,\n",
              "   1.6754869222640991,\n",
              "   14.300568208098412,\n",
              "   11.13438430428505],\n",
              "  9: [21.044421166181564,\n",
              "   3.1043923050165176,\n",
              "   13.53465436398983,\n",
              "   9.121602460741997,\n",
              "   1.484820917248726],\n",
              "  10: [6.943060725927353,\n",
              "   9.239816337823868,\n",
              "   9.091073706746101,\n",
              "   14.188378483057022,\n",
              "   5.211460471153259],\n",
              "  11: [23.6852914839983,\n",
              "   12.051261812448502,\n",
              "   0.4889354556798935,\n",
              "   16.055232137441635,\n",
              "   17.016854405403137],\n",
              "  12: [15.93766239285469,\n",
              "   1.6794832348823547,\n",
              "   13.339759886264801,\n",
              "   14.121163219213486,\n",
              "   1.2333553582429886],\n",
              "  13: [21.825827166438103,\n",
              "   0.9536149501800537,\n",
              "   13.543399080634117,\n",
              "   2.94871623814106,\n",
              "   10.647152230143547],\n",
              "  14: [14.15131202340126,\n",
              "   12.273041129112244,\n",
              "   17.232332974672318,\n",
              "   16.787004947662354,\n",
              "   4.183243632316589],\n",
              "  15: [12.621598541736603,\n",
              "   2.8679305762052536,\n",
              "   3.280889242887497,\n",
              "   3.5821392238140106,\n",
              "   13.548387125134468],\n",
              "  16: [18.43377135694027,\n",
              "   10.77748829126358,\n",
              "   13.88722337782383,\n",
              "   15.836062267422676,\n",
              "   3.94141061604023],\n",
              "  17: [22.113973662257195,\n",
              "   16.122446328401566,\n",
              "   11.561142355203629,\n",
              "   16.316033452749252,\n",
              "   9.108184650540352],\n",
              "  18: [27.769382506608963,\n",
              "   0.9416983127593994,\n",
              "   1.9096923917531967,\n",
              "   3.344245284795761,\n",
              "   4.566961824893951],\n",
              "  19: [4.195665270090103,\n",
              "   12.785741344094276,\n",
              "   16.429734244942665,\n",
              "   13.588114142417908,\n",
              "   1.2370485812425613],\n",
              "  20: [24.687782272696495,\n",
              "   14.925240144133568,\n",
              "   2.4456197023391724,\n",
              "   14.583852425217628,\n",
              "   12.819067806005478],\n",
              "  21: [16.84586536884308,\n",
              "   7.877346679568291,\n",
              "   1.681423544883728,\n",
              "   14.161396875977516,\n",
              "   16.33519969880581],\n",
              "  22: [7.735166788101196,\n",
              "   3.7369037121534348,\n",
              "   14.971168532967567,\n",
              "   3.381238102912903,\n",
              "   7.127163842320442],\n",
              "  23: [14.353522539138794,\n",
              "   1.703089103102684,\n",
              "   4.21835669875145,\n",
              "   2.385314494371414,\n",
              "   7.678983137011528],\n",
              "  24: [9.212541699409485,\n",
              "   12.571482479572296,\n",
              "   1.189331516623497,\n",
              "   14.217523887753487,\n",
              "   0.9789490550756454],\n",
              "  25: [12.543328583240509,\n",
              "   13.338664129376411,\n",
              "   1.6833261251449585,\n",
              "   2.1683958917856216,\n",
              "   15.976515844464302],\n",
              "  26: [8.829320162534714,\n",
              "   5.425677612423897,\n",
              "   15.517684876918793,\n",
              "   9.50240284204483,\n",
              "   4.190943151712418],\n",
              "  27: [7.51745879650116,\n",
              "   11.324099227786064,\n",
              "   4.528181686997414,\n",
              "   0.9585635811090469,\n",
              "   17.45272919535637],\n",
              "  28: [8.30006855726242,\n",
              "   3.4663027822971344,\n",
              "   8.534754484891891,\n",
              "   11.327862054109573,\n",
              "   4.162220016121864],\n",
              "  29: [23.775063306093216,\n",
              "   0.951821818947792,\n",
              "   1.675632044672966,\n",
              "   2.8931899666786194,\n",
              "   7.823523059487343],\n",
              "  30: [9.738638639450073,\n",
              "   0.9500390589237213,\n",
              "   5.268908724188805,\n",
              "   4.821732014417648,\n",
              "   12.067872136831284],\n",
              "  31: [22.85009877383709,\n",
              "   3.8245513290166855,\n",
              "   16.206231489777565,\n",
              "   15.580346509814262,\n",
              "   0.9884212613105774]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjKZxk7R7LjX",
        "outputId": "1d69bcd8-65a0-42da-b251-90a06c4ace51"
      },
      "source": [
        "generate_videos(model, video_name=\"Impala_dp5_200levels_test10\", save_video=True, nr_of_levels=10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved video: Impala_dp5_200levels_test10_level1_reward39.mp4\n",
            "Saved video: Impala_dp5_200levels_test10_level2_reward16.mp4\n",
            "Saved video: Impala_dp5_200levels_test10_level3_reward37.mp4\n",
            "Saved video: Impala_dp5_200levels_test10_level4_reward66.mp4\n",
            "Saved video: Impala_dp5_200levels_test10_level5_reward23.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0i_LTZ5eK2d"
      },
      "source": [
        "### Impala no penalty 200 levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05C_jfnteQdV"
      },
      "source": [
        "# #for Experiment 7\n",
        "# file_name = \"Experiment7_200levels_Run_06Dec_16h18m31s_loaded_07Dec_11h04m01s_7012352steps\"\n",
        "# set_hyperparameters(baseline=\"Impala\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 200\n",
        "# h.batch_size=512\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# model.load_policy(file_name)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUJucmgCebOs"
      },
      "source": [
        "# old_policy_evaluation(model)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O7TOF7Wfq0Z"
      },
      "source": [
        "### PPO 200 levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZrwNZ6mfq0Z"
      },
      "source": [
        "# #For Experiment 2\n",
        "# file_name = \"Experiment2_200levels_Run_07Dec_13h49m13s_loaded_08Dec_00h03m23s_7012352steps\"\n",
        "# set_hyperparameters(baseline=\"PPO\")\n",
        "# h.value_clipping = True\n",
        "# h.num_levels = 200\n",
        "# model = PPO(print_output=True, eval=True, save_interval=5e5)\n",
        "# policy=model.load_policy(file_name)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7hS8m4fq0a"
      },
      "source": [
        "# for i in range(4):\n",
        "#   result=old_policy_evaluation(model, video_name=\"PPO_200levels_{}\".format(i), off_set=i, print_output=False)\n",
        "#   print(\"{}: {}\".format(i, result))\n",
        "  "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEenEv_DhxGP"
      },
      "source": [
        "# old_policy_evaluation(model, test_on_training=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYIEoz--iNx2"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}