{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auto_Combining_from_multiple_csv.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "L6jlWJKXBo0m",
        "OBb1c_XBBsNl",
        "W-c7NK3rq2Fz",
        "leXvFEtCq6hW"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastianLarssonDTU/02456-Reinforcement-Learning-Project/blob/before_framestacking/Auto_Combining_from_multiple_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6jlWJKXBo0m"
      },
      "source": [
        "# INIT : Procgen, Drive, Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mmSs5ItNLLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c466de8c-fa07-447a-9a1c-9b067ca9bf0b"
      },
      "source": [
        "!pip install procgen"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting procgen\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/34/0ae32b01ec623cd822752e567962cfa16ae9c6d6ba2208f3445c017a121b/procgen-0.10.4-cp36-cp36m-manylinux2010_x86_64.whl (39.9MB)\n",
            "\u001b[K     |████████████████████████████████| 39.9MB 105kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (1.18.5)\n",
            "Requirement already satisfied: gym<1.0.0,>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (0.17.3)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (3.0.12)\n",
            "Collecting gym3<1.0.0,>=0.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/8c/83da801207f50acfd262041e7974f3b42a0e5edd410149d8a70fd4ad2e70/gym3-0.3.3-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.3.0)\n",
            "Collecting glfw<2.0.0,>=1.8.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/1b/cc758368f1b2466b3701c0f692973aa8a0b51a192a40463c1d02d54d640c/glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.0MB/s \n",
            "\u001b[?25hCollecting moderngl<6.0.0,>=5.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/ab/5f72a1b7c5bdbb17160c85e8ba855d48925c74ff93c1e1027d5ad40bf33c/moderngl-5.6.2-cp36-cp36m-manylinux1_x86_64.whl (664kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 34.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi<2.0.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.14.3)\n",
            "Collecting imageio<3.0.0,>=2.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.4MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/12/01126a2fb737b23461d7dadad3b8abd51ad6210f979ff05c6fa9812dfbbe/imageio_ffmpeg-0.3.0-py3-none-manylinux2010_x86_64.whl (22.2MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<1.0.0,>=0.15.0->procgen) (0.16.0)\n",
            "Collecting glcontext<3,>=2\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/8d/93915df9cd8d31c5f054bbacd1c7a76cd2f776b8212dcc768358bd2d4a37/glcontext-2.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi<2.0.0,>=1.13.0->gym3<1.0.0,>=0.3.3->procgen) (2.20)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0.0,>=2.6.0->gym3<1.0.0,>=0.3.3->procgen) (7.0.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: glfw, glcontext, moderngl, imageio, imageio-ffmpeg, gym3, procgen\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "Successfully installed glcontext-2.2.0 glfw-1.12.0 gym3-0.3.3 imageio-2.9.0 imageio-ffmpeg-0.3.0 moderngl-5.6.2 procgen-0.10.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RgF6myEA6WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19dd312a-fa07-471a-b1de-d447ba43a8bb"
      },
      "source": [
        "#Clone git\n",
        "!git clone -b restructure_code https://github.com/SebastianLarssonDTU/02456-Reinforcement-Learning-Project.git \"my_project\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'my_project'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 606 (delta 88), reused 2 (delta 0), pack-reused 460\u001b[K\n",
            "Receiving objects: 100% (606/606), 9.10 MiB | 21.36 MiB/s, done.\n",
            "Resolving deltas: 100% (371/371), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-jsbleFHMz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2dbd31-2cb9-4405-8d07-ad1e3cadf199"
      },
      "source": [
        "#update git\n",
        "%cd /content/my_project\n",
        "! git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/my_project\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abnnrXLuB6Ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc4d77b-e78c-4bd7-edd4-6a4577e4f0ae"
      },
      "source": [
        "import datatools as tools\n",
        "from datatools import DATA_PATH, MODEL_PATH\n",
        "#Mount drive\n",
        "tools.mount_drive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBb1c_XBBsNl"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XmB8QZ7BQIW"
      },
      "source": [
        "#Import all custom files\n",
        "import baseline\n",
        "import datatools as tools\n",
        "import hyperparameters as h\n",
        "import model\n",
        "import my_util\n",
        "import policy\n",
        "import ppo\n",
        "import utils\n",
        "\n",
        "#other imports\n",
        "import torch\n",
        "\n",
        "#import specific methods\n",
        "from baseline import set_hyperparameters\n",
        "from ppo import PPO\n",
        "from experiments import run_experiment, print_list_of_experiments\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnJTSTYQ3t1t"
      },
      "source": [
        "# Create Index File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRPwQn0pHiEZ"
      },
      "source": [
        "INDEX = tools.create_index_table_from_txt_files()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmTmfbqpqNIK"
      },
      "source": [
        "# Create .csv's\n",
        "\n",
        "Assumes that all file_names are correct! (with step count etc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC32JOGavp3Y"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvqqngcnqQTF"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def create_training_csv_from_multiple_runs(base_file_name):\n",
        "  all_related_files = find_related_csv_files(base_file_name)\n",
        "\n",
        "  #create a df for each file\n",
        "  dfs = []\n",
        "  for name in all_related_files:\n",
        "    dfs.append(pd.read_csv(DATA_PATH + name + \".csv\"))\n",
        "\n",
        "  dfs = remove_overlap_from_dfs(dfs)\n",
        "\n",
        "  #Concatenate\n",
        "  final_df = pd.concat(dfs)\n",
        "  final_df = final_df.set_index(\"Step\")\n",
        "\n",
        "  #Save to file\n",
        "  final_df.to_csv(DATA_PATH +base_file_name +\"_combined.csv\")\n",
        "\n",
        "def create_EVAL_csv_from_multiple_runs(base_file_name):\n",
        "  all_related_files = find_related_csv_files(base_file_name)\n",
        "  base = 32*256*16\n",
        "\n",
        "  dfs = []\n",
        "  for name in all_related_files:\n",
        "    df = pd.read_csv(DATA_PATH + name + \"_EVAL.csv\")\n",
        "    #add steps if missing\n",
        "    if \"step\" not in df.columns:\n",
        "      df.insert(0, \"Step\", [base*(i+1) for i in range(len(df))])\n",
        "    else:\n",
        "      df.rename(columns={'step':'Step'}, inplace=True)\n",
        "    dfs.append(df)\n",
        "\n",
        "  dfs = remove_overlap_from_dfs(dfs)\n",
        "\n",
        "  #Remove whitespace in headers\n",
        "  for df in dfs:\n",
        "    df.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "\n",
        "    #Concatenate\n",
        "  final_df = pd.concat(dfs)\n",
        "  final_df = final_df.set_index(\"Step\")\n",
        "\n",
        "  #save in file\n",
        "  final_df.to_csv(DATA_PATH +base_file_name +\"_combined_EVAL.csv\")\n",
        "\n",
        "\n",
        "def remove_overlap_from_dfs(dfs):\n",
        "  #Dataframes overlap, so cut off excess\n",
        "  breakpoints=[]\n",
        "  for df in dfs[1:]:\n",
        "    breakpoints.append(df['Step'][0])\n",
        "  for i in range(len(dfs)-1):\n",
        "    dfs[i] = dfs[i][dfs[i][\"Step\"] < breakpoints[i]]\n",
        "  return dfs\n",
        "\n",
        "def find_related_csv_files(base_file_name):\n",
        "  file_names = [x.strip() for x in INDEX['file_name']]\n",
        "  all_related_files= []\n",
        "  for name in file_names:\n",
        "    if base_file_name in name and \"combined\" not in name:\n",
        "      all_related_files.append(name)\n",
        "\n",
        "  return all_related_files\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-6sF1lfvmil"
      },
      "source": [
        "## Create files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73uSMNfisMUI"
      },
      "source": [
        "base_file_name = \"Experiment8_200levels_Run_06Dec_16h17m59s\"\n",
        "create_EVAL_csv_from_multiple_runs(base_file_name)\n",
        "create_training_csv_from_multiple_runs(base_file_name)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUhSclwtsQQK"
      },
      "source": [
        "base_file_name = \"Experiment7_200levels_Run_06Dec_16h18m31s\"\n",
        "create_EVAL_csv_from_multiple_runs(base_file_name)\n",
        "create_training_csv_from_multiple_runs(base_file_name)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVPLmX-au3Dp"
      },
      "source": [
        "base_file_name = \"Experiment2_200levels_Run_07Dec_13h49m13s\"\n",
        "create_EVAL_csv_from_multiple_runs(base_file_name)\n",
        "create_training_csv_from_multiple_runs(base_file_name)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQpIGDbeXICp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}