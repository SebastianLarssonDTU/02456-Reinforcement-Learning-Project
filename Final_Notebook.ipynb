{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastianLarssonDTU/02456-Reinforcement-Learning-Project/blob/clean-up-for-report/Final_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVCcg-BMGMOP"
      },
      "source": [
        "# About this notebook\r\n",
        "\r\n",
        "This notebook is created by Sebastian Larsson and Henriette Becker Kristiansen. It functions as supplementary material to the article found here.\r\n",
        "It has been created as part of the authors attending the course \"02456 Deep Learning\" at the Technical University of Denmark in the fall of 2020. \r\n",
        "\r\n",
        "*INSERT LINK*\r\n",
        "\r\n",
        "Running the whole notebook will do the following:\r\n",
        "\r\n",
        "*   Install needed packages used in the project\r\n",
        "*   Clone the git repository\r\n",
        "*   Load the trained models used in the article\r\n",
        "*   Run evaluation on one of the models\r\n",
        "*   Generate example videos from trained model\r\n",
        "\r\n",
        "Moreover this notebook contains snippets of code that is outcommented that can create and train new models using our implemented architectures.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6jlWJKXBo0m"
      },
      "source": [
        "# Initialisation\r\n",
        "\r\n",
        "First we need to install the needed Procgen benchmark that is needed to run the game on.\r\n",
        "\r\n",
        "Then we need to clone the git for access to all our own code.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mmSs5ItNLLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec975fc3-8939-452b-ab38-e541ecb30f68"
      },
      "source": [
        "!pip install procgen"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: procgen in /usr/local/lib/python3.6/dist-packages (0.10.4)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (3.0.12)\n",
            "Requirement already satisfied: gym3<1.0.0,>=0.3.3 in /usr/local/lib/python3.6/dist-packages (from procgen) (0.3.3)\n",
            "Requirement already satisfied: gym<1.0.0,>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (0.17.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (1.19.4)\n",
            "Requirement already satisfied: imageio<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (2.9.0)\n",
            "Requirement already satisfied: imageio-ffmpeg<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (0.3.0)\n",
            "Requirement already satisfied: glfw<2.0.0,>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.12.0)\n",
            "Requirement already satisfied: moderngl<6.0.0,>=5.5.4 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (5.6.2)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.14.4)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym<1.0.0,>=0.15.0->procgen) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0.0,>=2.6.0->gym3<1.0.0,>=0.3.3->procgen) (7.0.0)\n",
            "Requirement already satisfied: glcontext<3,>=2 in /usr/local/lib/python3.6/dist-packages (from moderngl<6.0.0,>=5.5.4->gym3<1.0.0,>=0.3.3->procgen) (2.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi<2.0.0,>=1.13.0->gym3<1.0.0,>=0.3.3->procgen) (2.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<1.0.0,>=0.15.0->procgen) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RgF6myEA6WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35eb1b13-53af-4d62-b801-f970c01fc688"
      },
      "source": [
        "#Clone git\n",
        "!git clone -b \"clean-up-for-report\" https://github.com/SebastianLarssonDTU/02456-Reinforcement-Learning-Project.git \"my_project\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'my_project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvb1_MqzGI1c"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-jsbleFHMz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30936d28-5670-43dd-ead4-477f73b9e9b1"
      },
      "source": [
        "#update git (in case of a restart and run all, then the project is already cloned)\n",
        "%cd /content/my_project\n",
        "! git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/my_project\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKT1UkeUE9ii"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abnnrXLuB6Ry"
      },
      "source": [
        "import datatools as tools\n",
        "import hyperparameters as h\n",
        "from ppo import PPO\n",
        "from baseline import set_hyperparameters"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksH8ZJJgF2tD"
      },
      "source": [
        "# Start training of new model from scratch\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyu1ikHSGAZ8"
      },
      "source": [
        "## Setting hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVBviH8DF9Yy"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRcr1QvKGDrV"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsuo8DXgGFv-"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeFS3FlFFqr6"
      },
      "source": [
        "# Loading trained models\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruVVHHekSvJe"
      },
      "source": [
        "levels=[10, 50, 200]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUH6moNASYMm"
      },
      "source": [
        "## Nature Architecture with Value clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJlrLWwFTKbW"
      },
      "source": [
        "nature_model_files={}\r\n",
        "\r\n",
        "nature_model_files[10] = \"Experiment2_Run_27Nov_11h05m48s\"\r\n",
        "nature_model_files[50] = \"Experiment2_50levels_Run_04Dec_18h10m32s_loaded_06Dec_12h08m48s_27541504steps\"  #bug in naming of files at the time of running this. True #steps is 8019968\r\n",
        "nature_model_files[200] = \"Experiment2_200levels_Run_07Dec_13h49m13s_loaded_08Dec_17h00m43s_8126464steps\"\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph5GYjncFs3y",
        "outputId": "2d921c1b-1a55-4909-d1a1-40abf4792437"
      },
      "source": [
        "#set hyperparameters\r\n",
        "set_hyperparameters(baseline=\"PPO\")\r\n",
        "h.value_clipping = True\r\n",
        "\r\n",
        "nature_models={}\r\n",
        "nature_models[0] =\"Nature\"\r\n",
        "\r\n",
        "for level in levels:\r\n",
        "  h.num_levels = level\r\n",
        "  model = PPO(print_output=True, eval=True, save_interval=5e5)\r\n",
        "  policy=model.load_policy(nature_model_files[level], model_path = \"/content/my_project/Trained models/\", data_path = \"/content/my_project/Data/\")\r\n",
        "  nature_models[level] = model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment2_Run_27Nov_11h05m48s.pt\n",
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment2_50levels_Run_04Dec_18h10m32s_loaded_06Dec_12h08m48s_27541504steps.pt\n",
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment2_200levels_Run_07Dec_13h49m13s_loaded_08Dec_17h00m43s_8126464steps.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0K4sl8sZpDG"
      },
      "source": [
        "## IMPALA architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMmBZyfOZs-K"
      },
      "source": [
        "impala_model_files={}\r\n",
        "\r\n",
        "impala_model_files[10] = \"Experiment7_Run_30Nov_14h45m32s\"\r\n",
        "impala_model_files[50] = \"Experiment7_50levels_Run_04Dec_18h12m45s_loaded_05Dec_10h49m07s_12517376steps\" #actual steps is 8011776\r\n",
        "impala_model_files[200] = \"Experiment7_200levels_Run_06Dec_16h18m31s_loaded_08Dec_14h21m55s_8019968steps\"\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR2hGLuqZz-F",
        "outputId": "c7cf51fc-b6e4-4eb9-870c-50fec401a0a3"
      },
      "source": [
        "#set hyperparameters\r\n",
        "set_hyperparameters(baseline=\"Impala\")\r\n",
        "h.value_clipping = True\r\n",
        "h.batch_size=512\r\n",
        "\r\n",
        "impala_models={}\r\n",
        "impala_models[0] = \"Impala\"\r\n",
        "\r\n",
        "for level in levels:\r\n",
        "  h.num_levels = level\r\n",
        "  model = PPO(print_output=True, eval=True, save_interval=5e5)\r\n",
        "  policy=model.load_policy(impala_model_files[level], model_path = \"/content/my_project/Trained models/\", data_path = \"/content/my_project/Data/\")\r\n",
        "  impala_models[level] = model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment7_Run_30Nov_14h45m32s.pt\n",
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment7_50levels_Run_04Dec_18h12m45s_loaded_05Dec_10h49m07s_12517376steps.pt\n",
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment7_200levels_Run_06Dec_16h18m31s_loaded_08Dec_14h21m55s_8019968steps.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnEFY7L9cD6e"
      },
      "source": [
        "## Impala with Death Penalty of 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQvG-9WIcHau"
      },
      "source": [
        "impala_dp5_model_files={}\r\n",
        "\r\n",
        "impala_dp5_model_files[10] = \"Experiment8_10levels_Run_07Dec_18h17m17s_loaded_08Dec_00h29m39s_7512064steps\"\r\n",
        "impala_dp5_model_files[50] = \"Experiment8_50levels_Run_05Dec_08h34m02s_loaded_08Dec_15h01m51s_8019968steps\"\r\n",
        "impala_dp5_model_files[200] = \"Experiment8_200levels_Run_06Dec_16h17m59s_loaded_08Dec_13h28m10s_8028160steps\"\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e6fVuVKc9en",
        "outputId": "45448f83-636f-4972-b2ca-1d86b5e99105"
      },
      "source": [
        "#set hyperparameters\r\n",
        "set_hyperparameters(baseline=\"Impala\")\r\n",
        "h.value_clipping = True\r\n",
        "h.batch_size=512\r\n",
        "h.death_penalty = True\r\n",
        "h.penalty = 5\r\n",
        "\r\n",
        "impala_dp5_models={}\r\n",
        "impala_dp5_models[0] = \"Impala with death penalty 5\"\r\n",
        "\r\n",
        "for level in levels:\r\n",
        "  h.num_levels = level\r\n",
        "  model = PPO(print_output=True, eval=True, save_interval=5e5)\r\n",
        "  policy=model.load_policy(impala_dp5_model_files[level], model_path = \"/content/my_project/Trained models/\", data_path = \"/content/my_project/Data/\")\r\n",
        "  impala_dp5_models[level] = model"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment8_10levels_Run_07Dec_18h17m17s_loaded_08Dec_00h29m39s_7512064steps.pt\n",
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment8_50levels_Run_05Dec_08h34m02s_loaded_08Dec_15h01m51s_8019968steps.pt\n",
            "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
            "Action space: 15\n",
            "Loaded current model from models folder with name Experiment8_200levels_Run_06Dec_16h17m59s_loaded_08Dec_13h28m10s_8028160steps.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoLjN022FvNQ"
      },
      "source": [
        "# Evaluate trained models\r\n",
        "\r\n",
        "This code will evaluate all the loaded models on X new unseen levels.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhF5UDB3FyIF"
      },
      "source": [
        "model_dics=[nature_models, impala_models, impala_dp5_models]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs2JMohufZp_",
        "outputId": "fbbbbba1-6faf-4b7e-eefc-00bc4fa8c352"
      },
      "source": [
        "nr_of_levels=5\r\n",
        "\r\n",
        "print(\"Starting evaluation of models on {} new unseen levels\".format(nr_of_levels))\r\n",
        "for dic in model_dics:\r\n",
        "  print(\"***** {} *****\".format(dic[0]))\r\n",
        "  for level in levels:\r\n",
        "    model = dic[level]\r\n",
        "    average_reward, rewards = model.evaluate_policy(nr_of_levels,\r\n",
        "                                                  print_output=False,\r\n",
        "                                                  normalize_reward = False) \r\n",
        "    #rewards will contain a dictionary of the rewards from each environment\r\n",
        "    #average_reward is the average pr. game across all environments\r\n",
        "    print(\"... trained on {:3.0f} levels got average reward pr game of {:.2f}\".format(level, average_reward))\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting evaluation of models on 5 new unseen levels\n",
            "***** Nature *****\n",
            "... trained on  10 levels got average reward pr game of 5.13\n",
            "... trained on  50 levels got average reward pr game of 12.31\n",
            "... trained on 200 levels got average reward pr game of 23.90\n",
            "***** Impala *****\n",
            "... trained on  10 levels got average reward pr game of 10.91\n",
            "... trained on  50 levels got average reward pr game of 20.57\n",
            "... trained on 200 levels got average reward pr game of 28.78\n",
            "***** Impala with death penalty 5 *****\n",
            "... trained on  10 levels got average reward pr game of 16.97\n",
            "... trained on  50 levels got average reward pr game of 15.32\n",
            "... trained on 200 levels got average reward pr game of 40.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tolHoLHkjq3"
      },
      "source": [
        "# Generate video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DSLcHUbkxQq"
      },
      "source": [
        "## Code modified from given example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-B2w07RgGAB"
      },
      "source": [
        "from utils import make_env\r\n",
        "import imageio\r\n",
        "import torch\r\n",
        "\r\n",
        "VIDEO_PATH = '/content/'\r\n",
        "\r\n",
        "def generate_videos(model, video_name=None, print_output=True, test_on_training=False, off_set = 0, nr_of_levels=5, save_video=False, dist_mode=\"easy\"):\r\n",
        "  policy = model.policy\r\n",
        "\r\n",
        "  if video_name is None:\r\n",
        "    video_name = model.file_name\r\n",
        "  \r\n",
        "  # Make evaluation environment\r\n",
        "  if test_on_training:\r\n",
        "    eval_env = make_env(model.num_envs, num_levels=model.num_levels, normalize_reward = False, dist_mode=dist_mode)\r\n",
        "    video_name += \"_TEST_ON_TRAINING\"\r\n",
        "  else:\r\n",
        "    eval_env = make_env(model.num_envs, start_level=model.num_levels+off_set, num_levels=model.num_levels, normalize_reward = False, dist_mode=dist_mode)\r\n",
        "  obs = eval_env.reset()\r\n",
        "\r\n",
        "  frames = []\r\n",
        "  total_reward = []\r\n",
        "  level_counter=1\r\n",
        "  # Evaluate policy\r\n",
        "  policy.eval()\r\n",
        "\r\n",
        "  while True:\r\n",
        "    \r\n",
        "    # Use policy\r\n",
        "    action, log_prob, value = policy.act(obs)\r\n",
        "\r\n",
        "    # Take step in environment\r\n",
        "    obs, reward, done, info = eval_env.step(action)\r\n",
        "    total_reward.append(torch.Tensor(reward))\r\n",
        "\r\n",
        "    # Render environment and store\r\n",
        "    frame = (torch.Tensor(eval_env.render(mode='rgb_array'))*255.).byte()\r\n",
        "    frames.append(frame)\r\n",
        "    if done[0]: #next level\r\n",
        "      #Calculate level reward\r\n",
        "      level_reward = torch.stack(total_reward).sum(0)[0]\r\n",
        "      \r\n",
        "      if save_video:\r\n",
        "        # Save frames as video\r\n",
        "        frames = torch.stack(frames).cpu().numpy()\r\n",
        "        name = video_name+'_level{:d}_reward{:.0f}.mp4'.format(level_counter, level_reward)\r\n",
        "        imageio.mimsave(VIDEO_PATH + name, frames, fps=25)\r\n",
        "        print(\"Saved video: {}\".format(name))\r\n",
        "      else:\r\n",
        "        print(level_counter)\r\n",
        "        print(level_reward)\r\n",
        "      \r\n",
        "      #check if all levels done\r\n",
        "      level_counter +=1\r\n",
        "      if level_counter > nr_of_levels:\r\n",
        "        break #done testing\r\n",
        "\r\n",
        "      #reset variables for next level\r\n",
        "      frames=[]\r\n",
        "      total_reward = []"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w8yKb7OlD05"
      },
      "source": [
        "## Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0PpFtewm7kz"
      },
      "source": [
        "model = impala_dp5_models[200]\r\n",
        "video_name= \"Impala_dp5\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1qhWz4JlGm4",
        "outputId": "825bf7eb-5a95-475c-edfe-1389ad9b79b2"
      },
      "source": [
        "generate_videos(model, video_name=video_name, save_video=True, nr_of_levels=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved video: Impala_dp5_level1_reward20.mp4\n",
            "Saved video: Impala_dp5_level2_reward19.mp4\n",
            "Saved video: Impala_dp5_level3_reward8.mp4\n",
            "Saved video: Impala_dp5_level4_reward14.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hx9MCtGnUAK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}